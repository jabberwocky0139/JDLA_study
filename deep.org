** 何かつくりたいもの
Deefocusな画像からInfocusな画像を生成する.


** 過学習
過学習しやすい条件
- モデルの自由度が高い
- 特徴量が多い
- データが少ない

正則化: lambda
大きな傾向を捉えるのが目的. 変なフィッティングを目指さずに
正則化でゆるーく見る.

L1: ラッソ sparse → 正則化項としては使い物になる.
L2: リッチ sparseでない.
リッチ回帰とか.

ホワイトニング 0-1に抑える

Data Augmentation
→ データの水増し
業務として必要な水増しの方法を知るべき.

CNNはデータの回転とかに弱い.
→ カプセルネットワーク. 

モデルにノイズを加える

半教師あり学習.
k-近傍法: 重心でクラスタリング
davy-scan: 密度でクラスタリング

マルチタスク学習

early-stopping

パラメータ共有
→人間が恣意的に重みを適当に与えてあげる
→ネコの耳とかの特徴の重みを強くする

スパース表現
主成分でない重みは軽くしていく.
←→主成分分析
いらないデータはまず消す、が先.
特徴選択は既に終えている前提、くらいのイメージ


バギング
Bootstrap Aggregation
→ アンサンブル学習の一種. 
A, B, C並列で解析

Boosting
A, B, C直列で解析
それぞれの重みをゆるくしておく
ゆるいものを直列でつなげていく

→Kaggle: xgboost
ただのアンサンブル機械学習. DeepLearningで使える.

Dropout
ネットワークの一部を非活性にする. 
学習するたびに非活性のノードは変える. / 正則化やアンサンブルと似たような.

RFE
Recursive Feature Selection


** 最適化手法
性能と精度.
精度はそこそこで、性能をどうやって上げるか.
ミニバッチ: GPUへのメモリ転送を効率よく. 重みは変えない.
オンライン: 重みを毎度変えていく. DLではあまり使わない.

DNNには鞍点(プラトー)がたくさんある
勾配クリッピング: 勾配がキツくなったらステップを細かくする

長期依存性
RNNだとよく出てくる. 勾配消失が特によく起きる(爆発よりも)

アルゴリズムめっちゃある
SGDやらRMSProp・Adamとか.
SGDのよいところは、ランダムにサンプリングすること.

Lanczosフィルター
Bellフィルター

どんだけ減らしても500バリエーション程度はないとまともに動かない.
10,000くらいはあると結構いい精度が出たりする.
カプセルネットワークとかは、気合と根性でどうにかしない方法を模索している.
転移学習.

統計ベース / ルールベース / モデルベース

スモールデータからモデルの検証をする

初期値の設定
Xavier / He

★共変量シフト
ホワイトニング: 1-100 → -50→50 (平均を0にする) & 標準偏差を1にする
共変量シフトを回避するための方法がBatchNormalization.
(実は回避できない...)

教師あり事前学習
CIFAR-10(MNISTよりあたらしい. 最近はよく使われる)
VGG-16(16相のネットワーク) / ResNet

既存のモデルを使いながら16相あるうちの最後の層のみを学習する(15相をFreeze)
→はやい！転移学習ともいう
NAS: Neural Architecture Search
 AutoML


** CNN
1989: DeepLeaningが無い頃からあった
第二次AIブームのころ

CNN
+ Comvolution
  - Filter: X,Y
  - Stride: X,Y
+ Pooling: 特徴を残して次元圧縮する

CNNは回転に弱いので、入力データを回転させて水増し
拡大・縮小にも弱い

+ カプセルネットワーク
 - スカッシュ
  
CNNは並列計算向き
RNNは向かない → QRNN: CNNベース
CNNは自然の画像に向いている

CNNの先端
YOLO
OpenPose
EdgeTPU
EdgePOD


** CNNの代表定期なモデル
無機物の認識がムズい. 職人芸.
まだちゃんと定式化できていない.
VGG: 積乱雲か何雲か、、、とかはわからないが、雲であることはわかる.
     猫の種類は案外わかる. 
     VGGでできることがCNNでできること、と思って良い.

複数チャンネル: 色別に分けた画像を入れたり、白黒とカラーを同時に入れたり.

ResNetよりもVGG16のほうが今は主流.
ResNetはいいモデルなんだけど、重い.
層が50もあると勾配が消失しやすい.

アンサンブル学習: Random Forest / 勾配Boosting 残差を学習.
弱学習機x10

ショートカットルートを創ることにより、より強いネットワークができあがる.
層を増やすより重要. google automlでは飛ばし方のチューニングもできる.

TensorFlow Hub: 転移学習に使える


** RNN
attention

Word2Vec

tensorflow/example


** GAN
<余談>
AI/MLドリブンではなく、システム開発の延長上にMLがある.

オーバーサンプリング: 0/1の数に偏りがあるときに、同じデータを入れてリバランスする
alpha go: 生成モデルで似たデータを生成する.


** JDLA対策
E検定例題
*教材の中のことばの定義をすべて正確に把握する.*
*計算式は考えてね*

* JDLA対策ノート
** 概要
    E資格のシラバスにある内容をざっくりまとめていく.
    あくまで、ざっくりです. 厳密性に欠けることはご容赦下さい.
** 応用数学
*** 線形代数
**** 特異値分解
     任意の $m \times n$ 行列Aを、 $A = U\Sigma V$ のような積に分解することを特異値分解という.
     Uはm x mの直交行列、 $V$ は $n \times n$ の直交行列、 $\Sigma$ は $m \times n$ の非対角成分が0の行列.
     $\Sigma$の非ゼロ成分のことを特異値と呼ぶ.
     参考: <https://mathtrain.jp/svd>

     これが果たして何に役に立つのかというと、どうやら画像の圧縮や情報検索に応用されるようです.
     行列Aが以下のように分解されるとしましょう:
     #      \begin{eqnarray*}
     #   A &=& \left(
     #     \begin{array}{cc}
     #       a & b \\
     #       c & d 
     #     \end{array}
     #   \right)
     #   \left(
     #     \begin{array}{ccc}
     #       x & 0 & 0\\
     #       0 & y & 0
     #     \end{array}
     #   \right)
     #   \left(
     #     \begin{array}{cc}
     #       e & f\\
     #       g & h\\
     #       i & j
     #     \end{array}
     #   \right)\\
     #   &=& x\left(
     #     \begin{array}{c}
     #       a \\
     #       c 
     #     \end{array}
     #   \right)
     #   \left(
     #     \begin{array}{cc}
     #       e & f
     #     \end{array}
     #   \right)
     #   + y\left(
     #     \begin{array}{c}
     #       b \\
     #       d 
     #     \end{array}
     #   \right)
     #   \left(
     #     \begin{array}{cc}
     #       g & h
     #     \end{array}
     #   \right)\\
     #   &=& xu_1v_1^{\mathrm{T}} + yu_2v_2^{\mathrm{T}}
     # \end{eqnarray*}
     行列Aは 特異値を係数とする $u_kv_k^{\mathrm{T}}$ という行列の線型結合で書けることになります.
     仮に画像が100 x 100pixだったとして、これを100 x 100行列Aと見なします. Aの特異値がk個だとすると、要素の個数は k x (100 + 100)となります. kが少なければ情報量は大幅に削減できることになります.
     式を見てわかるとおり線型結合となる行列$u_kv_k^{\mathrm{T}}$の重みは特異値になるので、大きい特異値のみを拾ってくるとさらに要素を圧縮できます.
     


